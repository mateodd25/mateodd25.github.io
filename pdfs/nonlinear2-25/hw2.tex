% Created 2025-02-16 Sun 23:13
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{bm}
\hypersetup{colorlinks=true}
\usepackage[left=1.125in,right=1.1in,top=1.1in,bottom=1.125in]{geometry}
\titleformat{\section}[block]{\Large\bfseries\filcenter}{}{1em}{}
\newcommand{\RR}{\mathbf{R}}
\newcommand{\E}{\mathbf{E}}
\newcommand{\EEE}{\mathbf{E}}
\newcommand{\YY}{\mathbf{Y}}
\newcommand{\Spp}{\mathbf{S}_{++}^n}
\newcommand{\Sp}{\mathbf{S}_{+}^n}
\newcommand{\SSS}{\mathbf{S}^n}
\newcommand{\bR}{\overline{\mathbf{R}}}
\newcommand{\prox}{\operatorname{prox}}
\newcommand{\epi}{\operatorname{epi}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\dom}{\operatorname{dom}}
\newcommand{\Tr}{\operatorname{tr}}
\usepackage{algorithm}
\usepackage{algpseudocode}
\date{}
\title{}
\hypersetup{
 pdfauthor={Mateo Diaz},
 pdftitle={},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 30.0.93 (Org mode 9.7.19)}, 
 pdflang={English}}
\usepackage{biblatex}

\begin{document}

\section*{\textbf{Nonlinear Optimization 2, Spring 2025 - Homework 2} \\ Due at 11:49PM on Friday 2/28 (Gradescope)}
\label{sec:org414c513}
\textbf{Your submitted solutions to assignments should be your own work. You are allowed to discuss homework problems with other students, but should carry out the execution of any thoughts/directions discussed independently, on your own. Acknowledge any source you consult.}
\textbf{\textcolor{red}{Do not use any type of Large Language Model, e.g., ChatGPT, to blindly answer this assignment. If you do, your submission will be voided and you will get zero as a grade.}} \vspace{.5cm}
\subsection*{Problem 1 - Directional derivative formulae}
\label{sec:org7243844}
\begin{itemize}
\item[(a)] Let $f \colon \EEE \rightarrow \RR$ be continuous and directionally differentiable at zero such that there exists $g\in \EEE$ satisfying  $f'(x; v) = \langle g, v \rangle$ for all $v \in \EEE$. Find a counterexample to show that this does not necessarily imply that $f$ is differentiable at zero.
\item[(b)] Let $f \colon \EEE \rightarrow \RR \cup \{+ \infty\}$ be a proper, closed, convex function. Let $x \in \dom f$, show that for any $v$, the directional derivative $f'(x, v)$ exists and, moreover, it is equal to $$ f'(x; v) = \sup_{g \in \partial f(x)} \langle g, v\rangle \quad \text{for all }x, v \in \EEE.$$
\item[(c)] Let $f_{1}, \dots, f_{k} \colon \EEE \rightarrow \RR$ be differentiable functions and define $h(x) = \max_{j \in [k]} f_{j}(x)$. Prove that $h$ is directionally differentiable for any $v \in \EEE.$ Further, prove that
$$
h'(x; v) = \max_{j \in [k]} \langle \nabla f_{j}(x), v\rangle \quad \text{for all }x, v \in \EEE.
$$
\end{itemize}
\subsection*{Problem 2 - Arguments that we missed}
\label{sec:org5104dd5}
Show the following two things we did not prove in class.
\begin{enumerate}
\item[(a)] Let $f\colon \EEE \rightarrow \RR \cup \{+\infty\}$ and $g\colon \EEE \rightarrow \RR \cup \{+\infty\}$ be convex functions, and $A \colon \EEE \rightarrow \YY$ be a linear map. Define the value function $\nu \colon \YY \rightarrow \RR \cup \{\pm \infty\}$ given by $
\nu(z) = \inf_{x \in \EEE} f(x) + g(Ax + z).
$
\begin{itemize}
\item[(1)] Show that $\nu$ is a convex function.
\item[(2)] In Lecture 6, we concluded that if $v(0)$ is finite and $0 \in \rm{int}\left\{ \dom(g) - A \dom(f)\right\}$, then there exists a $y \in \partial \nu(0)$. To do this we used the "Existance of subgradients" Theorem from Lecture 4. However, this theorem only applies to functions whose image land in $\RR \cup \{+\infty\}$, why can we apply it to $\nu$? (Recall that we saw an example where $\nu(1) = - \infty$ in Lecture 7).
\end{itemize}
\item[(b)] Let $a_{1}, \dots, a_{m} \in \EEE$ be an arbitrary collection of points. Consider the following three statements.
\begin{itemize}
\item[(1)] The function $f(x) = \log\left(\sum_{i \in [m]} \exp\left(\langle a_{i}, x\rangle \right) \right)$ is bounded below.
\item[(2)] There exists a vector $\lambda \in \RR^{m}_{+}$ such that $\sum_{i \in [m]} \lambda_{i} = 1$ and $\sum_{i \in [m]}\lambda_{i} a_{i} = 0$.
\item[(3)] There is no vector  $x \in \EEE$ such that  $\langle a_{i}, x\rangle < 0$ for all $i \in [m]$.
\end{itemize}
In class we proved that $(1)$ implies $(2).$ Show that $(2)$ implies $(3)$ and $(3)$ implies $(1)$.
\end{enumerate}
\subsection*{Problem 3 - Duality with cones}
\label{sec:orgcb654f4}
\begin{enumerate}
\item[(a)] (\textbf{Krein-Rutman Theorem}) Consider a linear map $A \colon \EEE \rightarrow \YY$, and the indicator functions of convex cones $K \subseteq \EEE$ and $H\subseteq \YY$. Compute $\partial \iota_{K}(0)$ and use subdifferential calculus to find conditions guaranteeing $\left(K\cap A^{{-1}} H \right)^{+} = K^{ +} + A^{*} H^{ +}$ where $A^{-1} H = \{x \in \EEE \mid Ax \in H\}.$
\item[(b)] Given a nonempty set $K \subseteq \EEE$, by considering $\iota_{K}^{**}$, prove $K = K^{ + +}$ if, and only if, $K$ is a closed convex cone.
\item[(c)] Suppose that the closed convex cones $K \subseteq \EEE$ and $H\subseteq \EEE$ satisfy the condition $K^{ +} \cap \rm{int }\, H^{ +} \neq \emptyset$. Prove $K + H$ is closed.
\item[(d)] Prove the sum of the closed convex cones in $\RR^{2} \times \RR$
$$
\{(x, r) \mid \|x\|_{2} \leq r\} \quad \text{and} \quad \{(x, r) \mid x_{1}=0, r=x_{2}\}
$$
is not closed. \textbf{Hint:} consider the point $-(1,1,1)$.
\end{enumerate}
\subsection*{Problem 4 - Von Neumann Minimax Theorem}
\label{sec:org6269813}
Suppose the sets \(C\subseteq \EEE\) and \(D \subseteq \YY\) are nonempty and convex, with \(D\) closed.
\begin{enumerate}
    \item[(a)] By considering the Fenchel problem
$$
\inf_{x} \left\{\iota_{C}(x) + \iota^{*}_{D}(Ax)\right\}
$$
prove that if either of the next conditions hold
\begin{itemize}
\item[(i)] $D$ is bounded,
\item[(ii)] $A$ is surjective and $0 \in \rm{int }\,C$,
\end{itemize}
then
$$
\inf_{x \in C} \sup_{y \in D}\langle Ax, y \rangle =\sup_{y \in D} \inf_{x \in C} \langle Ax, y \rangle
$$
where the supremum on the right is attained whenever finite.
    \item[(b)] If both $C$ and $D$ are compact, prove
$$
\min_{x \in C} \max_{y \in D}\langle Ax, y \rangle =\max_{y \in D} \min_{x \in C} \langle Ax, y \rangle
$$
where all the maxima and minima are attained.
\end{enumerate}
\end{document}
